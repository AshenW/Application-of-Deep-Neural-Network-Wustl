{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy.stats import zscore\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import lightgbm as lgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "import warnings, gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "def multi_merge(left,right,*args):\n",
    "    start = args[0]\n",
    "    for i in range(1,len(args)):\n",
    "        start = start.merge(args[i], how = 'left', left_on = left, right_on = right)\n",
    "    return start\n",
    "\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(\n",
    "        target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type not in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    # Regression\n",
    "    return df[result].values.astype(np.float32), df[[target]].values.astype(np.float32)\n",
    "\n",
    "def clean_data(df,year):\n",
    "    column_list = list(df.columns)\n",
    "    A_list = [column for column in column_list if re.match(r'^[A][0-9]{2,10}',column) or re.match(r'^[a][0-9]{2,10}',column)]\n",
    "    N_list = [column for column in column_list if re.match(r'^[N][0-9]{2,10}',column) or re.match(r'^[n][0-9]{2,10}',column)]\n",
    "    O_list = [column for column in column_list if (column not in A_list and column not in N_list and column not in ['STATE','STATEFIPS','state','statefips'])]\n",
    "    if 'n1' in O_list:\n",
    "        N1 = 'n1'\n",
    "    else:\n",
    "        N1 = 'N1'\n",
    "    special = []\n",
    "    pair = []\n",
    "    for name in A_list:\n",
    "        if 'N' + name[1:] not in N_list and 'n' + name[1:] not in N_list:\n",
    "            special.append(name)\n",
    "        else:\n",
    "            pair.append(name)\n",
    "            if 'n' + name[1:] in N_list:\n",
    "                pair.append('n' + name[1:])\n",
    "            else:\n",
    "                pair.append('N' + name[1:])\n",
    "    special = O_list + special\n",
    "    pair = pair + ['zipcode',N1]\n",
    "    df_special = df.loc[:,special]\n",
    "    df_pair = df.loc[:,pair]\n",
    "    for column in list(df_special.columns):\n",
    "        if column != 'zipcode':\n",
    "            df_special[column] = df_special[column]/df_special[N1]\n",
    "    df_special = df_special.groupby(by='zipcode').agg('mean')\n",
    "    #print(df_special)\n",
    "    for name in N_list:\n",
    "        if name[0] == 'N':\n",
    "            A_name = 'A' + name[1:]\n",
    "        else:\n",
    "            A_name = 'a' + name[1:]\n",
    "        df_pair[A_name] = df_pair[A_name]/df_pair[name]\n",
    "        df_pair[name] = df_pair[name]/df_pair[N1]\n",
    "    #print(df_pair)\n",
    "    df_pair = df_pair.groupby(by='zipcode').mean().drop(N1,axis=1)\n",
    "    #print(df_pair)\n",
    "    df_result = df_special.merge(df_pair,how='inner',left_on='zipcode',right_on='zipcode').drop([N1,'agi_stub'],axis=1)\n",
    "    #print(df_pair.shape)\n",
    "    #print(df_special.shape)\n",
    "    #print(df_result.shape)\n",
    "    result_name_list = [name  if name == 'zipcode' else name + '_' + year for name in list(df_result.columns)]\n",
    "    df_result.columns = result_name_list\n",
    "    return df_result\n",
    "\n",
    "def normalization(x):\n",
    "    min_x = min(x)\n",
    "    max_x = max(x)\n",
    "    return np.array([(i-min_x)/(max_x-min_x) for i in x])\n",
    "\n",
    "def zscore_transformation(df):\n",
    "    for name in df.columns:\n",
    "        df[name] = zscore(df[name])\n",
    "    return df.dropna(axis=1).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network using one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cbp = pd.read_csv('./zbp16totals.csv')\n",
    "df_2016 = pd.read_csv('./16zpallagi.csv')\n",
    "df_train = pd.read_csv('./train.csv')\n",
    "df_test = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cbp['est'] = zscore(df_cbp['est'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.merge(df_cbp,how='left',left_on='zipcode',right_on='zip')\n",
    "df_test = df_test.merge(df_cbp,how='left',left_on='zipcode',right_on='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.loc[:,['est','score']]\n",
    "df_test = df_test.loc[:,['est']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = to_xy(df_train,'score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Epoch 00217: early stopping\n",
      "Fold score (RMSE): 0.26963096857070923\n",
      "Fold #2\n",
      "Epoch 00236: early stopping\n",
      "Fold score (RMSE): 0.2748175263404846\n",
      "Fold #3\n",
      "Epoch 00249: early stopping\n",
      "Fold score (RMSE): 0.2648850381374359\n",
      "Fold #4\n",
      "Fold score (RMSE): 0.2755565941333771\n",
      "Fold #5\n",
      "Epoch 00205: early stopping\n",
      "Fold score (RMSE): 0.2741800844669342\n",
      "Final score (RMSE): 0.2718437612056732\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "kf = KFold(5)\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "for train,test in kf.split(x):\n",
    "    fold += 1\n",
    "    print('Fold #{}'.format(fold))\n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x.shape[1], activation='relu',kernel_regularizer=regularizers.l2(0.01),\\\n",
    "                    activity_regularizer=regularizers.l1(0.01)))\n",
    "    #model.add(Dense(75, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    #model.add(Dense(50, activation='relu',kernel_regularizer=regularizers.l2(0.01),\\\n",
    "                    #activity_regularizer=regularizers.l1(0.01)))\n",
    "    #model.add(Dense(25, activation='relu',kernel_regularizer=regularizers.l2(0.01),\\\n",
    "                    #activity_regularizer=regularizers.l1(0.01)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-2, patience=25, verbose=1, mode='auto')\n",
    "    checkpointer = ModelCheckpoint(filepath=\"midterm_model1_best\", verbose=0, save_best_only=True)\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=0,epochs=250)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred)\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = metrics.mean_squared_error(oos_pred,oos_y)\n",
    "print(\"Final score (RMSE): {}\".format(np.sqrt(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_test = df_test.values.astype(np.float32)\n",
    "pred_test = model.predict(true_test)\n",
    "pred_test = model.predict(true_test)\n",
    "final_test_score = np.concatenate(pred_test)\n",
    "\n",
    "df_id = pd.read_csv('./test.csv')\n",
    "df_id['score'] = final_test_score\n",
    "df_id = df_id.loc[:,['id','score']]\n",
    "df_id.to_csv('csv_to_submit_regularization.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting some of the scores to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29872, 142)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "df_id_2 = copy.copy(df_id)\n",
    "df_id_2['score'] = df_id_2['score'].apply(lambda x: x if 0.45<x-int(x) and x-int(x)<0.55 else np.round(x))\n",
    "df_id_2.set_index('id',inplace = True)\n",
    "df_id_2.to_csv('range_05.csv')\n",
    "df_2016_result = clean_data(df_2016,'2016')\n",
    "df_2016_result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network with five features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = clean_data(df_2016,'2016')\n",
    "df_cbp = df_cbp.loc[:,['zip','emp','qp1','ap','est']]\n",
    "df_2016_result = df_2016_result.merge(df_2016_business,how='left',left_on='zipcode',right_on='zip')\n",
    "df_2016_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016_result_2 = df_2016_result.fillna(0)\n",
    "for name in df_2016_result_2.columns:\n",
    "    if name != 'zip':\n",
    "        df_2016_result_2[name] = normalization(df_2016_result_2[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29872, 147)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016_result_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./train.csv')\n",
    "df_test = pd.read_csv('./test.csv')\n",
    "df_train = df_train.merge(df_2016_result_2,how='left',left_on='zipcode',right_on='zip').drop(['id','zipcode','zip'],axis=1)\n",
    "df_test = df_test.merge(df_2016_result_2,how='left',left_on='zipcode',right_on='zip').drop(['id','zipcode','zip'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_sub = df_train.loc[:,['A00100_2016','emp','qp1','ap','est','score']]\n",
    "df_test_sub = df_test.loc[:,['A00100_2016','emp','qp1','ap','est']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = to_xy(df_train_sub,'score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mars1_2016</th>\n",
       "      <th>MARS2_2016</th>\n",
       "      <th>MARS4_2016</th>\n",
       "      <th>PREP_2016</th>\n",
       "      <th>N2_2016</th>\n",
       "      <th>NUMDEP_2016</th>\n",
       "      <th>TOTAL_VITA_2016</th>\n",
       "      <th>VITA_2016</th>\n",
       "      <th>TCE_2016</th>\n",
       "      <th>VITA_EIC_2016</th>\n",
       "      <th>...</th>\n",
       "      <th>A85300_2016</th>\n",
       "      <th>N85300_2016</th>\n",
       "      <th>A11901_2016</th>\n",
       "      <th>N11901_2016</th>\n",
       "      <th>A11902_2016</th>\n",
       "      <th>N11902_2016</th>\n",
       "      <th>emp</th>\n",
       "      <th>qp1</th>\n",
       "      <th>ap</th>\n",
       "      <th>est</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039987</td>\n",
       "      <td>0.055645</td>\n",
       "      <td>0.014787</td>\n",
       "      <td>0.038045</td>\n",
       "      <td>0.049725</td>\n",
       "      <td>0.029456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008939</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.064722</td>\n",
       "      <td>0.375671</td>\n",
       "      <td>0.009448</td>\n",
       "      <td>0.710278</td>\n",
       "      <td>0.004631</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.014254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009197</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>0.008238</td>\n",
       "      <td>0.010402</td>\n",
       "      <td>0.011242</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044508</td>\n",
       "      <td>0.276923</td>\n",
       "      <td>0.008956</td>\n",
       "      <td>0.782949</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.002193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012662</td>\n",
       "      <td>0.006805</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.007927</td>\n",
       "      <td>0.005159</td>\n",
       "      <td>0.006085</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055978</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.132176</td>\n",
       "      <td>0.504042</td>\n",
       "      <td>0.011297</td>\n",
       "      <td>0.559206</td>\n",
       "      <td>0.019085</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.008498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011596</td>\n",
       "      <td>0.015853</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>0.013080</td>\n",
       "      <td>0.008987</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056094</td>\n",
       "      <td>0.497667</td>\n",
       "      <td>0.008781</td>\n",
       "      <td>0.619012</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.005208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 146 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mars1_2016  MARS2_2016  MARS4_2016  PREP_2016   N2_2016  NUMDEP_2016  \\\n",
       "0    0.039987    0.055645    0.014787   0.038045  0.049725     0.029456   \n",
       "1    0.009197    0.009608    0.008238   0.010402  0.011242     0.009186   \n",
       "2    0.002666    0.004003    0.000000   0.003853  0.001441     0.002330   \n",
       "3    0.012662    0.006805    0.005809   0.008668  0.007927     0.005159   \n",
       "4    0.011596    0.015853    0.003802   0.011847  0.013080     0.008987   \n",
       "\n",
       "   TOTAL_VITA_2016  VITA_2016  TCE_2016  VITA_EIC_2016    ...     A85300_2016  \\\n",
       "0         0.000000   0.000000       0.0            0.0    ...        0.008939   \n",
       "1         0.000000   0.000000       0.0            0.0    ...        0.000000   \n",
       "2         0.000000   0.000000       0.0            0.0    ...        0.000000   \n",
       "3         0.006085   0.013575       0.0            0.0    ...        0.055978   \n",
       "4         0.000000   0.000000       0.0            0.0    ...        0.000000   \n",
       "\n",
       "   N85300_2016  A11901_2016  N11901_2016  A11902_2016  N11902_2016       emp  \\\n",
       "0     0.234375     0.064722     0.375671     0.009448     0.710278  0.004631   \n",
       "1     0.000000     0.044508     0.276923     0.008956     0.782949  0.000881   \n",
       "2     0.000000     0.000000     0.000000     0.006405     0.666667  0.000030   \n",
       "3     0.446429     0.132176     0.504042     0.011297     0.559206  0.019085   \n",
       "4     0.000000     0.056094     0.497667     0.008781     0.619012  0.001270   \n",
       "\n",
       "        qp1        ap       est  \n",
       "0  0.000568  0.000881  0.014254  \n",
       "1  0.000117  0.000155  0.002193  \n",
       "2  0.000009  0.000012  0.000685  \n",
       "3  0.006599  0.007481  0.008498  \n",
       "4  0.000145  0.000214  0.005208  \n",
       "\n",
       "[5 rows x 146 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Fold score (RMSE): 0.2908724844455719\n",
      "Fold #2\n",
      "Fold score (RMSE): 0.3195555508136749\n",
      "Fold #3\n",
      "Fold score (RMSE): 0.29362648725509644\n",
      "Fold #4\n",
      "Fold score (RMSE): 0.29371967911720276\n",
      "Fold #5\n",
      "Fold score (RMSE): 0.2938407063484192\n",
      "Final score (RMSE): 0.2985142767429352\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "kf = KFold(5)\n",
    "oos_y = []\n",
    "oos_pred = []\n",
    "fold = 0\n",
    "for train,test in kf.split(x):\n",
    "    fold += 1\n",
    "    print('Fold #{}'.format(fold))\n",
    "    x_train = x[train]\n",
    "    y_train = y[train]\n",
    "    x_test = x[test]\n",
    "    y_test = y[test]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=x.shape[1], activation='relu',kernel_regularizer=regularizers.l2(0.01),\\\n",
    "                    activity_regularizer=regularizers.l1(0.01)))\n",
    "    #model.add(Dense(75, activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
    "    #model.add(Dense(50, activation='relu',kernel_regularizer=regularizers.l2(0.01),\\\n",
    "                    #activity_regularizer=regularizers.l1(0.01)))\n",
    "    #model.add(Dense(25, activation='relu',kernel_regularizer=regularizers.l2(0.01),\\\n",
    "                    #activity_regularizer=regularizers.l1(0.01)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-2, patience=25, verbose=1, mode='auto')\n",
    "    checkpointer = ModelCheckpoint(filepath=\"midterm_model1_best\", verbose=0, save_best_only=True)\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=0,epochs=250)\n",
    "    \n",
    "    pred = model.predict(x_test)\n",
    "    oos_y.append(y_test)\n",
    "    oos_pred.append(pred)\n",
    "    score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "    print(\"Fold score (RMSE): {}\".format(score))\n",
    "\n",
    "oos_y = np.concatenate(oos_y)\n",
    "oos_pred = np.concatenate(oos_pred)\n",
    "score = metrics.mean_squared_error(oos_pred,oos_y)\n",
    "print(\"Final score (RMSE): {}\".format(np.sqrt(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_test = df_test_sub.values.astype(np.float32)\n",
    "pred_test = model.predict(true_test)\n",
    "pred_test = model.predict(true_test)\n",
    "final_test_score = np.concatenate(pred_test)\n",
    "\n",
    "df_id = pd.read_csv('./test.csv')\n",
    "df_id['score'] = final_test_score\n",
    "df_id = df_id.loc[:,['id','score']]\n",
    "df_id.to_csv('csv_to_submit_regularization.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./train.csv')\n",
    "df_test = pd.read_csv('./test.csv')\n",
    "df_feature = pd.read_csv('./zbp16totals.csv')\n",
    "df_train = df_train.merge(df_feature,how='left',left_on='zipcode',right_on='zip')\n",
    "df_test = df_test.merge(df_feature,how='left',left_on='zipcode',right_on='zip')\n",
    "df_train = df_train.loc[:,['score','emp','qp1','ap','est']]\n",
    "df_test = df_test.loc[:,['emp','qp1','ap','est']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "corr = df_train.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5467</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4725</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2097</td>\n",
       "      <td>43</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1244</td>\n",
       "      <td>71</td>\n",
       "      <td>98</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>891</td>\n",
       "      <td>99</td>\n",
       "      <td>126</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>731</td>\n",
       "      <td>127</td>\n",
       "      <td>154</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>593</td>\n",
       "      <td>155</td>\n",
       "      <td>182</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>481</td>\n",
       "      <td>183</td>\n",
       "      <td>210</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>477</td>\n",
       "      <td>211</td>\n",
       "      <td>238</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>396</td>\n",
       "      <td>239</td>\n",
       "      <td>266</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  min  max  range\n",
       "score                        \n",
       "0       5467    1   14     13\n",
       "1       4725   15   42     27\n",
       "2       2097   43   70     27\n",
       "3       1244   71   98     27\n",
       "4        891   99  126     27\n",
       "5        731  127  154     27\n",
       "6        593  155  182     27\n",
       "7        481  183  210     27\n",
       "8        477  211  238     27\n",
       "9        396  239  266     27"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_est = df_train.loc[:,['score','est']]\n",
    "df_score_summary = df_score_est.groupby(by='score').apply(lambda x: pd.Series({'count':x.shape[0],\\\n",
    "                                                                               'min':min(x.est),\\\n",
    "                                                                               'max':max(x.est),\\\n",
    "                                                                               'range':max(x.est)-min(x.est)}))\n",
    "df_score_summary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
